#!/usr/bin/env python

from __future__ import division

import argparse

from hyperopt import fmin, hp, tpe, STATUS_FAIL, STATUS_OK

from lasvegas import constants, eval, train
from lasvegas.state import create_model


parser = argparse.ArgumentParser()
parser.add_argument('-n', '--training-games', default=1000, type=int,
                    help='number of games to use during training')
parser.add_argument('-N', '--eval-games', default=1000, type=int,
                    help='number of games to use during evaluation')
parser.add_argument('-e', '--max-evals', default=50, type=int,
                    help='maximum number of models to evaluate')
args = parser.parse_args()

# Define the space of hyperparameters to tune
space = {
    'DISCOUNT_RATE': hp.uniform('DISCOUNT_RATE', 0.5, 0.9),
    'EPSILON': hp.uniform('EPSILON', 0, 0.1),
    'LEARNING_MEMORY_SIZE': hp.quniform('LEARNING_MEMORY_SIZE', 50, 10000, 50),
    'MINIBATCH_SIZE': hp.quniform('MINIBATCH_SIZE', 1, 100, 10),
    'TIE_REWARD': hp.uniform('TIE_REWARD', 1, 500),
    'WIN_REWARD': hp.uniform('WIN_REWARD', 1, 1000)
}


def objective(params):
    """
    Train and evaluate the model using the given parameters,
    scoring each model with wins + draws / 2
    """
    global args, eval_num

    eval_num += 1
    print('\n Eval %d' % eval_num)

    # Check that the parameters are valid
    if params['TIE_REWARD'] > params['WIN_REWARD'] or \
       params['MINIBATCH_SIZE'] > params['LEARNING_MEMORY_SIZE']:
        return {'loss': None, 'status': STATUS_FAIL}

    # Convert necessary parameters to integers
    params['LEARNING_MEMORY_SIZE'] = int(params['LEARNING_MEMORY_SIZE'])
    params['MINIBATCH_SIZE'] = int(params['MINIBATCH_SIZE'])

    # Apply all the parameters
    for (key, val) in params.items():
        setattr(constants, key, val)

    model = create_model()
    train.train_model(model, args.training_games, 'changing')
    stats = eval.eval_model('model', args.eval_games, 'changing', model)

    return {'loss': -(stats['wins'] + stats['draws'] / 2), 'status': STATUS_OK}

# Perform hyperparameter optimization and print the results
eval_num = 0
best = fmin(objective, space, algo=tpe.suggest, max_evals=args.max_evals)
print('')
for (key, val) in best.items():
    print('%s = %s' % (key, str(val)))
